# =============================================================================
# FKS Paper Trading Test Workflow
# =============================================================================
# Deploys and monitors a 48-hour paper trading soak test on the production server.
#
# âš ï¸ IMPORTANT: RUNNER REQUIREMENTS
# ----------------------------------
# GitHub-hosted runners have a 6-hour maximum job timeout. This workflow uses
# long sleep intervals in health check jobs that WILL FAIL on GitHub-hosted
# runners for tests longer than ~5 hours.
#
# SOLUTIONS:
# 1. Use a SELF-HOSTED RUNNER (recommended) - change `runs-on: ubuntu-latest`
#    to `runs-on: self-hosted` in the health check and final-report jobs
# 2. For shorter tests (â‰¤5 hours), GitHub-hosted runners work fine
# 3. See the generic `soak-test.yml` template for a restructured approach
#
# Features:
# - Manual trigger with configurable options
# - Paper trading mode (no real orders)
# - Optimizer hot-reload testing
# - Periodic health checks (1h, 6h, 24h checkpoints)
# - Discord notifications for status updates
# - Automatic log collection
#
# Usage:
#   Trigger manually from GitHub Actions UI with desired options
#
# Required Secrets:
# - PROD_SSH_KEY, PROD_SSH_USER, PROD_SSH_PORT
# - PROD_TAILSCALE_IP (server's Tailscale IP, e.g., 100.x.x.x)
# - TAILSCALE_OAUTH_CLIENT_ID, TAILSCALE_OAUTH_SECRET
# - DOCKER_USERNAME, DOCKER_TOKEN (if rebuilding images)
# - DISCORD_WEBHOOK_ACTIONS (optional, for notifications)
# =============================================================================

name: ğŸ§ª Paper Trading Test

on:
    workflow_dispatch:
        inputs:
            duration_hours:
                description: "Test duration in hours"
                required: false
                type: choice
                options:
                    - "1"
                    - "12"
                    - "24"
                    - "48"
                    - "72"
                    - "96"
                    - "168"
                    - "720"
                default: "48"
            assets:
                description: "Assets to trade (comma-separated)"
                required: false
                type: string
                default: "BTC,ETH,SOL,AVAX,LINK,MATIC,ARB,OP,DOGE,XRP"
            optimize_interval:
                description: "Optimization interval"
                required: false
                type: choice
                options:
                    - "1h"
                    - "2h"
                    - "4h"
                    - "6h"
                    - "12h"
                default: "6h"
            optimize_trials:
                description: "Optimization trials per asset"
                required: false
                type: choice
                options:
                    - "20"
                    - "50"
                    - "100"
                default: "50"

            clean_volumes:
                description: "Clean volumes before starting (fresh DB)"
                required: false
                type: boolean
                default: false
            run_initial_optimization:
                description: "Run optimization immediately on start"
                required: false
                type: boolean
                default: true

permissions:
    contents: read
    actions: write

env:
    REGISTRY: docker.io
    IMAGE_NAME: nuniesmith/fks
    TEST_ID: "${{ inputs.duration_hours }}hr-${{ github.run_number }}-${{ github.run_attempt }}"

concurrency:
    group: paper-trading-test
    cancel-in-progress: false # Don't cancel running tests

jobs:
    # ===========================================================================
    # STAGE 1: SETUP AND VALIDATION
    # ===========================================================================
    setup:
        name: ğŸ“‹ Setup Test
        runs-on: ubuntu-latest
        timeout-minutes: 5
        outputs:
            test_id: ${{ steps.config.outputs.test_id }}
            start_time: ${{ steps.config.outputs.start_time }}
            end_time: ${{ steps.config.outputs.end_time }}
            duration_seconds: ${{ steps.config.outputs.duration_seconds }}
        steps:
            - name: ğŸ¯ Configure test parameters
              id: config
              run: |
                  START_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
                  DURATION_HOURS=${{ inputs.duration_hours }}
                  DURATION_SECONDS=$((DURATION_HOURS * 3600))
                  END_TIME=$(date -u -d "+${DURATION_HOURS} hours" +"%Y-%m-%dT%H:%M:%SZ")

                  echo "test_id=${{ env.TEST_ID }}" >> $GITHUB_OUTPUT
                  echo "start_time=$START_TIME" >> $GITHUB_OUTPUT
                  echo "end_time=$END_TIME" >> $GITHUB_OUTPUT
                  echo "duration_seconds=$DURATION_SECONDS" >> $GITHUB_OUTPUT

                  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
                  echo "â•‘           48-HOUR PAPER TRADING TEST CONFIGURATION           â•‘"
                  echo "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"
                  echo "â•‘  Test ID:      ${{ env.TEST_ID }}"
                  echo "â•‘  Duration:     ${DURATION_HOURS} hours"
                  echo "â•‘  Assets:       ${{ inputs.assets }}"
                  echo "â•‘  Optimizer:    ${{ inputs.optimize_interval }} interval, ${{ inputs.optimize_trials }} trials"
                  echo "â•‘  Start:        $START_TIME"
                  echo "â•‘  End:          $END_TIME"
                  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

            - name: ğŸ” Validate secrets
              env:
                  HAS_SSH_KEY: ${{ secrets.PROD_SSH_KEY != '' }}
                  HAS_TAILSCALE_IP: ${{ secrets.PROD_TAILSCALE_IP != '' }}
                  HAS_TAILSCALE_ID: ${{ secrets.TAILSCALE_OAUTH_CLIENT_ID != '' }}
                  HAS_TAILSCALE_SECRET: ${{ secrets.TAILSCALE_OAUTH_SECRET != '' }}
              run: |
                  ERRORS=""

                  if [ "$HAS_SSH_KEY" != "true" ]; then
                    ERRORS="${ERRORS}\n  - PROD_SSH_KEY"
                  fi
                  if [ "$HAS_TAILSCALE_IP" != "true" ]; then
                    ERRORS="${ERRORS}\n  - PROD_TAILSCALE_IP"
                  fi
                  if [ "$HAS_TAILSCALE_ID" != "true" ]; then
                    ERRORS="${ERRORS}\n  - TAILSCALE_OAUTH_CLIENT_ID"
                  fi
                  if [ "$HAS_TAILSCALE_SECRET" != "true" ]; then
                    ERRORS="${ERRORS}\n  - TAILSCALE_OAUTH_SECRET"
                  fi

                  if [ -n "$ERRORS" ]; then
                    echo -e "âŒ Missing required secrets:$ERRORS"
                    exit 1
                  fi
                  echo "âœ… All required secrets present"
                  echo "ğŸ¯ Target host will use PROD_TAILSCALE_IP secret"

    # ===========================================================================
    # STAGE 2: DEPLOY AND START TEST
    # ===========================================================================
    deploy:
        name: ğŸš€ Deploy Test
        runs-on: ubuntu-latest
        timeout-minutes: 20
        needs: setup
        outputs:
            deployed: ${{ steps.deploy.outputs.deployed }}
        steps:
            - name: ğŸ“¥ Checkout code
              uses: actions/checkout@v4

            - name: ğŸ”Œ Connect to Tailscale
              id: tailscale
              uses: nuniesmith/actions/.github/actions/tailscale-connect@main
              with:
                  oauth-client-id: ${{ secrets.TAILSCALE_OAUTH_CLIENT_ID }}
                  oauth-secret: ${{ secrets.TAILSCALE_OAUTH_SECRET }}
                  target-ip: ${{ secrets.PROD_TAILSCALE_IP }}
                  target-ssh-port: ${{ secrets.PROD_SSH_PORT || '22' }}

            - name: ğŸš€ Deploy Paper Trading Test
              id: deploy
              uses: nuniesmith/actions/.github/actions/ssh-deploy@main
              with:
                  host: ${{ secrets.PROD_TAILSCALE_IP }}
                  port: ${{ secrets.PROD_SSH_PORT || '22' }}
                  username: ${{ secrets.PROD_SSH_USER || 'actions' }}
                  ssh-key: ${{ secrets.PROD_SSH_KEY }}
                  project-path: ~/fks
                  git-pull: "true"
                  git-branch: ${{ github.ref_name }}
                  docker-pull: "true"
                  pre-deploy-command: |
                      echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
                      echo "ğŸ§ª PREPARING ${{ inputs.duration_hours }}-HOUR PAPER TRADING TEST"
                      echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

                      # System info
                      echo "ğŸ–¥ï¸  Host: $(hostname) | $(date)"
                      echo "ğŸ’¾ Disk: $(df -h / | tail -1 | awk '{print $4}') free | Memory: $(free -h | grep Mem | awk '{print $7}') available"

                      # Create test configuration
                      TEST_DURATION="${{ inputs.duration_hours }}"
                      TEST_ENV_FILE=".env.${TEST_DURATION}hr-test"
                      cat > "$TEST_ENV_FILE" << 'ENVEOF'
                      # ${{ inputs.duration_hours }}-Hour Paper Trading Test Configuration
                      # Test ID: ${{ needs.setup.outputs.test_id }}
                      # Generated: ${{ needs.setup.outputs.start_time }}

                      # ============================================
                      # TRADING MODE - SIMULATION (Paper Trading)
                      # ============================================
                      TRADING_MODE=simulation
                      REAL_ORDERS_ENABLED=false

                      # ============================================
                      # Execution Service
                      # ============================================
                      ENABLE_EXECUTION=true
                      EXECUTION_EXCHANGE=kraken
                      BYBIT_TESTNET=true

                      # ============================================
                      # Risk Limits (Conservative for testing)
                      # ============================================
                      MAX_POSITION_SIZE=100
                      MAX_DAILY_LOSS=50
                      MAX_OPEN_ORDERS=5

                      # ============================================
                      # Optimizer Configuration
                      # ============================================
                      OPTIMIZER_ENABLED=true
                      OPTIMIZE_INTERVAL=${{ inputs.optimize_interval }}
                      OPTIMIZE_ASSETS=${{ inputs.assets }}
                      OPTIMIZE_TRIALS=${{ inputs.optimize_trials }}
                      OPTIMIZE_HISTORICAL_DAYS=14
                      OPTIMIZER_INSTANCE_ID=${{ needs.setup.outputs.test_id }}

                      # ============================================
                      # Database
                      # ============================================
                      POSTGRES_USER=fks_user
                      POSTGRES_DB=fks

                      # ============================================
                      # Test Metadata
                      # ============================================
                      TEST_ID=${{ needs.setup.outputs.test_id }}
                      TEST_START_TIME=${{ needs.setup.outputs.start_time }}
                      TEST_DURATION_HOURS=${{ inputs.duration_hours }}
                      ENVEOF

                      # Load existing .env passwords and append to test config file
                      if [ -f .env ]; then
                        # Extract only password lines from existing .env (avoid duplicates)
                        grep -E "^(POSTGRES_PASSWORD|REDIS_PASSWORD|QUESTDB_PASSWORD|GRAFANA_PASSWORD)=" .env | head -4 >> "$TEST_ENV_FILE" 2>/dev/null || true
                      fi

                      # Create test log directory
                      NOW=$(date +%Y%m%d-%H%M%S | tr -d '\n')
                      TEST_LOG_DIR="logs/${TEST_DURATION}hr-test-$NOW"
                      mkdir -p "$TEST_LOG_DIR"
                      echo "TEST_LOG_DIR=$TEST_LOG_DIR" >> "$TEST_ENV_FILE"

                      echo "âœ… Test configuration created at $TEST_ENV_FILE"
                      echo "ğŸ“„ Test env file contents:"
                      wc -l "$TEST_ENV_FILE"

                  deploy-command: |
                      echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
                      echo "ğŸš€ STARTING ${{ inputs.duration_hours }}-HOUR PAPER TRADING TEST"
                      echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

                      # Docker login
                      echo "${{ secrets.DOCKER_TOKEN }}" | docker login -u "${{ secrets.DOCKER_USERNAME }}" --password-stdin docker.io || true

                      # IMPORTANT: Use separate env files instead of appending to prevent duplication
                      # Docker compose will merge both files, with later values taking precedence
                      # Do NOT append .env.48hr-test to .env - this causes massive duplication!

                      # Source both env files for shell commands
                      TEST_DURATION="${{ inputs.duration_hours }}"
                      TEST_ENV_FILE=".env.${TEST_DURATION}hr-test"
                      set -a
                      [ -f .env ] && source .env
                      [ -f "$TEST_ENV_FILE" ] && source "$TEST_ENV_FILE"
                      set +a

                      # Define compose command with BOTH env files (test file takes precedence)
                      COMPOSE_CMD="docker compose --env-file .env --env-file $TEST_ENV_FILE -f infrastructure/compose/docker-compose.yml -f infrastructure/compose/docker-compose.prod.yml"
</text>

<old_text line=340>
                      # Start background log collection
                      if [ -z "$TEST_LOG_DIR" ]; then
                        TEST_LOG_DIR=$(grep TEST_LOG_DIR .env.48hr-test 2>/dev/null | tail -1 | cut -d= -f2)
                      fi

                      # Deploy with run.sh prod or direct compose
                      chmod +x ./run.sh 2>/dev/null || true
                      if [ -x "./run.sh" ]; then
                        # Clean volumes if requested
                        if [ "${{ inputs.clean_volumes }}" = "true" ]; then
                          echo "ğŸ§¹ Cleaning volumes..."
                          ./run.sh prod down -v 2>/dev/null || true
                        else
                          echo "ğŸ›‘ Stopping existing containers..."
                          ./run.sh prod down 2>/dev/null || true
                        fi

                        # Pull latest images using both env files
                        echo "ğŸ“¥ Pulling images..."
                        $COMPOSE_CMD pull --ignore-pull-failures 2>&1 || true

                        # Start services
                        echo "ğŸš€ Starting services..."
                        ./run.sh prod start 2>&1
                      else
                        if [ "${{ inputs.clean_volumes }}" = "true" ]; then
                          $COMPOSE_CMD down -v --remove-orphans 2>/dev/null || true
                        else
                          $COMPOSE_CMD down --remove-orphans 2>/dev/null || true
                        fi
                        $COMPOSE_CMD pull --ignore-pull-failures 2>&1 || true
                        $COMPOSE_CMD up -d 2>&1
                      fi

                      echo "â³ Waiting for services to start..."
                      sleep 30

                      # Run initial optimization if requested
                      if [ "${{ inputs.run_initial_optimization }}" = "true" ]; then
                        echo "ğŸ”§ Running initial optimization..."
                        docker exec fks_janus /app/janus-optimizer run-once --quick --assets "${{ inputs.assets }}" 2>&1 || echo "âš ï¸ Initial optimization had issues"
                      fi

                      # Start background log collection
                      if [ -z "$TEST_LOG_DIR" ]; then
                        TEST_LOG_DIR=$(grep TEST_LOG_DIR "$TEST_ENV_FILE" 2>/dev/null | tail -1 | cut -d= -f2)
                      fi
                      mkdir -p "$TEST_LOG_DIR"

                      # Collect all services combined log (capture stderr separately for debugging)
                      nohup docker compose --env-file .env --env-file "$TEST_ENV_FILE" -f infrastructure/compose/docker-compose.yml -f infrastructure/compose/docker-compose.prod.yml logs -f --timestamps >> "$TEST_LOG_DIR/all-services.log" 2> "$TEST_LOG_DIR/log-collector.err" &
                      COLLECTOR_PID=$!
                      echo $COLLECTOR_PID > "$TEST_LOG_DIR/log-collector.pid"

                      # Verify log collector started
                      sleep 2
                      if ps -p $COLLECTOR_PID > /dev/null 2>&1; then
                        echo "âœ… Combined log collector started (PID: $COLLECTOR_PID)"
                        sleep 1
                        if [ -s "$TEST_LOG_DIR/all-services.log" ]; then
                          echo "âœ… all-services.log is receiving data"
                        else
                          echo "âš ï¸ all-services.log is empty - check $TEST_LOG_DIR/log-collector.err"
                          [ -s "$TEST_LOG_DIR/log-collector.err" ] && cat "$TEST_LOG_DIR/log-collector.err"
                        fi
                      else
                        echo "âŒ Log collector failed to start! Check $TEST_LOG_DIR/log-collector.err"
                        [ -s "$TEST_LOG_DIR/log-collector.err" ] && cat "$TEST_LOG_DIR/log-collector.err"
                      fi

                      # Collect individual service logs (verify containers exist first)
                      for svc in janus execution redis postgres questdb; do
                        if docker ps --filter "name=fks_${svc}" --format '{{.Names}}' | grep -q "fks_${svc}"; then
                          nohup docker logs -f "fks_${svc}" >> "$TEST_LOG_DIR/${svc}.log" 2>&1 &
                        fi
                      done

                      echo ""
                      echo "ğŸ“ Log collection started:"
                      echo "   - $TEST_LOG_DIR/all-services.log (combined, PID: $COLLECTOR_PID)"
                      echo "   - $TEST_LOG_DIR/janus.log"
                      echo "   - $TEST_LOG_DIR/execution.log"
                      echo "   - $TEST_LOG_DIR/redis.log"
                      echo "   - $TEST_LOG_DIR/postgres.log"
                      echo "   - $TEST_LOG_DIR/questdb.log"
                      echo ""
                      echo "ğŸ’¡ If all-services.log is empty, check: $TEST_LOG_DIR/log-collector.err"
                      echo "ğŸ’¡ To restart log collection: cd ~/fks && nohup docker compose -f infrastructure/compose/docker-compose.yml -f infrastructure/compose/docker-compose.prod.yml logs -f >> $TEST_LOG_DIR/all-services.log 2>&1 &"

                      # Create helper script for checking status
                      cat > "$TEST_LOG_DIR/check-status.sh" << 'STATUSEOF'
                      #!/bin/bash
                      echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
                      echo "ğŸ“Š PAPER TRADING TEST STATUS"
                      echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
                      echo ""
                      echo "ğŸ“¦ Container Status:"
                      docker ps -a --filter "name=fks" --format "table {{.Names}}\t{{.Status}}\t{{.RunningFor}}"
                      echo ""
                      echo "ğŸ’¾ Memory Usage:"
                      docker stats --no-stream --format "table {{.Name}}\t{{.MemUsage}}\t{{.CPUPerc}}" | grep fks
                      echo ""
                      echo "ğŸ“ˆ Recent Janus Logs (last 50 lines):"
                      docker logs fks_janus --tail 50 2>&1
                      echo ""
                      echo "ğŸ”§ Optimizer Status:"
                      docker exec fks_janus /app/janus-optimizer status 2>&1 || echo "Could not get optimizer status"
                      STATUSEOF
                      chmod +x "$TEST_LOG_DIR/check-status.sh"

                      # Save test metadata
                      cat > "$TEST_LOG_DIR/test-info.json" <<EOFTEST
                      {
                        "test_id": "${{ needs.setup.outputs.test_id }}",
                        "test_type": "${{ inputs.duration_hours }}hr_paper_trading",
                        "start_time": "${{ needs.setup.outputs.start_time }}",
                        "expected_end_time": "${{ needs.setup.outputs.end_time }}",
                        "duration_hours": ${{ inputs.duration_hours }},
                        "mode": "simulation",
                        "real_orders_enabled": false,
                        "assets": "${{ inputs.assets }}",
                        "optimize_interval": "${{ inputs.optimize_interval }}",
                        "optimize_trials": ${{ inputs.optimize_trials }},
                        "github_run_id": "${{ github.run_id }}",
                        "github_sha": "${{ github.sha }}",
                        "triggered_by": "${{ github.actor }}"
                      }
EOFTEST

                      # Show status
                      echo ""
                      echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
                      echo "â•‘              48-HOUR TEST DEPLOYED SUCCESSFULLY              â•‘"
                      echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
                      echo ""
                      echo "ğŸ“Š Container Status:"
                      docker ps -a --filter "name=fks" --format "table {{.Names}}\t{{.Status}}" | head -15
                      echo ""
                      echo "ğŸ“ Logs: $TEST_LOG_DIR"
                      echo ""
                      echo "ğŸ’¡ To check status later, run:"
                      echo "   cd ~/fks && $TEST_LOG_DIR/check-status.sh"
                      echo ""
                      echo "ğŸ’¡ To tail logs:"
                      echo "   tail -f $TEST_LOG_DIR/janus.log"

                      # Check container count
                      RUNNING=$(docker ps --filter "name=fks" --format '{{.Names}}' | wc -l)
                      echo "âœ… Running containers: $RUNNING"

                  post-deploy-command: |
                      echo ""
                      echo "ğŸ” Quick health check..."

                      # Check optimizer status
                      docker exec fks_janus /app/janus-optimizer status 2>&1 | head -20 || echo "âš ï¸ Optimizer status check failed"

                      echo ""
                      echo "âœ… Deployment complete! Test is running."

            - name: ğŸ“£ Notify test started
              if: steps.deploy.outputs.deployed == 'true'
              uses: nuniesmith/actions/.github/actions/discord-notify@main
              continue-on-error: true
              with:
                  webhook-url: ${{ secrets.DISCORD_WEBHOOK_ACTIONS }}
                  title: "ğŸ§ª 48-Hour Paper Trading Test Started"
                  description: "Paper trading soak test has been deployed and started."
                  status: success
                  include-repo-info: true
                  fields: |
                      Test ID|${{ needs.setup.outputs.test_id }}|true
                      Duration|${{ inputs.duration_hours }} hours|true
                      Assets|${{ inputs.assets }}|true
                      Optimizer|${{ inputs.optimize_interval }} / ${{ inputs.optimize_trials }} trials|true
                      Start Time|${{ needs.setup.outputs.start_time }}|false
                      Expected End|${{ needs.setup.outputs.end_time }}|false
